{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DhLlS5JkHe9i"
   },
   "source": [
    "# U-Net Segmentation\n",
    "\n",
    "A more sophisticated approach is needed to segment the wires from the images. Multiple ones are available but the first one used is the U-Net. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yoKXyqI4He9r"
   },
   "source": [
    "Use pytorch to define the unet model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "k0nBAUVFHe9u",
    "outputId": "c60e38ff-ddc9-478c-a8e2-65640275f8b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda:0 ...\n"
     ]
    }
   ],
   "source": [
    "# import modules (download with pip install first if not on local. Type on terminal: pip install <module name>)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F #contains some useful functions like activation functions & convolution operations you can use\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device(\"cuda: 0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using\",device,\"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fIWepn7sHe90"
   },
   "outputs": [],
   "source": [
    "# install torchvision first\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, datasets, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6oAL36EJHe8P"
   },
   "outputs": [],
   "source": [
    "from load_data import *\n",
    "# X, y = load_data('/content/drive/My Drive/AIWIRE', 'dataset')\n",
    "X, y = load_data('.', 'dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "5oPqkXM8He96",
    "outputId": "1310af7c-6e61-4e14-d53f-c7d6feca4c67"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 4000, 'val': 1000}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# implement Simulation of Dataset \n",
    "class SimDataset(Dataset):\n",
    "    def __init__(self, count,mode,transform=None):\n",
    "\n",
    "# Simulate from matlab engine \n",
    "#        for i in tqdm(range(count)):\n",
    "#            ground_truth, simulated = eng.simulate(1.3, 15, 0, nargout=2)\n",
    "#            _simulated += [simulated]\n",
    "#            _ground_truth += [ground_truth]\n",
    "        if mode == '_train': \n",
    "          _simulated = X[0:int(count*X.shape[0])]\n",
    "          _ground_truth = y[0:int(count*y.shape[0])]\n",
    "        elif mode == '_val': \n",
    "          _simulated = X[-(int(count*X.shape[0])):]\n",
    "          _ground_truth = y[-(int(count*y.shape[0])):]\n",
    "\n",
    "        self.input_images, self.target_masks = np.array(_simulated), np.array(_ground_truth)\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.input_images)\n",
    "    \n",
    "    def __getitem__(self, idx):        \n",
    "        image = self.input_images[idx]\n",
    "        mask = self.target_masks[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return [image, mask]\n",
    "\n",
    "# Tranform into pytorch tensors \n",
    "trans = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Create a train set and a validation set, each with input images (simulation data) and target masks (ground truth data)\n",
    "train_set = SimDataset(0.8,'_train',transform = trans)\n",
    "val_set = SimDataset(0.2,'_val',transform = trans)\n",
    "\n",
    "image_datasets = {\n",
    "    'train': train_set, 'val': val_set\n",
    "}\n",
    "\n",
    "batch_size = 100\n",
    "\n",
    "dataloaders = {\n",
    "    'train': DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=0),\n",
    "    'val': DataLoader(val_set, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "}\n",
    "\n",
    "dataset_sizes = {\n",
    "    x: len(image_datasets[x]) for x in image_datasets.keys()\n",
    "}\n",
    "\n",
    "dataset_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 1, 192, 128]) torch.Size([100, 192, 128])\n",
      "torch.float64 torch.float64\n",
      "9.822084046327182e-07 0.033971910984036915 0.003998812810005199 0.003363975758811057\n",
      "0.0 1.0 0.010246988932291666 0.10070743840508088\n",
      "MODEL ARCHITECTURE ...\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 32, 192, 128]             320\n",
      "              ReLU-2         [-1, 32, 192, 128]               0\n",
      "            Conv2d-3         [-1, 32, 192, 128]           9,248\n",
      "              ReLU-4         [-1, 32, 192, 128]               0\n",
      "         MaxPool2d-5           [-1, 32, 96, 64]               0\n",
      "            Conv2d-6           [-1, 64, 96, 64]          18,496\n",
      "              ReLU-7           [-1, 64, 96, 64]               0\n",
      "            Conv2d-8           [-1, 64, 96, 64]          36,928\n",
      "              ReLU-9           [-1, 64, 96, 64]               0\n",
      "        MaxPool2d-10           [-1, 64, 48, 32]               0\n",
      "           Conv2d-11          [-1, 128, 48, 32]          73,856\n",
      "             ReLU-12          [-1, 128, 48, 32]               0\n",
      "           Conv2d-13          [-1, 128, 48, 32]         147,584\n",
      "             ReLU-14          [-1, 128, 48, 32]               0\n",
      "        MaxPool2d-15          [-1, 128, 24, 16]               0\n",
      "           Conv2d-16          [-1, 256, 24, 16]         295,168\n",
      "             ReLU-17          [-1, 256, 24, 16]               0\n",
      "           Conv2d-18          [-1, 256, 24, 16]         590,080\n",
      "             ReLU-19          [-1, 256, 24, 16]               0\n",
      "        MaxPool2d-20           [-1, 256, 12, 8]               0\n",
      "           Conv2d-21           [-1, 512, 12, 8]       1,180,160\n",
      "             ReLU-22           [-1, 512, 12, 8]               0\n",
      "           Conv2d-23           [-1, 512, 12, 8]       2,359,808\n",
      "             ReLU-24           [-1, 512, 12, 8]               0\n",
      "         Upsample-25          [-1, 512, 24, 16]               0\n",
      "           Conv2d-26          [-1, 256, 24, 16]       1,769,728\n",
      "             ReLU-27          [-1, 256, 24, 16]               0\n",
      "           Conv2d-28          [-1, 256, 24, 16]         590,080\n",
      "             ReLU-29          [-1, 256, 24, 16]               0\n",
      "         Upsample-30          [-1, 256, 48, 32]               0\n",
      "           Conv2d-31          [-1, 128, 48, 32]         442,496\n",
      "             ReLU-32          [-1, 128, 48, 32]               0\n",
      "           Conv2d-33          [-1, 128, 48, 32]         147,584\n",
      "             ReLU-34          [-1, 128, 48, 32]               0\n",
      "         Upsample-35          [-1, 128, 96, 64]               0\n",
      "           Conv2d-36           [-1, 64, 96, 64]         110,656\n",
      "             ReLU-37           [-1, 64, 96, 64]               0\n",
      "           Conv2d-38           [-1, 64, 96, 64]          36,928\n",
      "             ReLU-39           [-1, 64, 96, 64]               0\n",
      "         Upsample-40         [-1, 64, 192, 128]               0\n",
      "           Conv2d-41         [-1, 32, 192, 128]          27,680\n",
      "             ReLU-42         [-1, 32, 192, 128]               0\n",
      "           Conv2d-43         [-1, 32, 192, 128]           9,248\n",
      "             ReLU-44         [-1, 32, 192, 128]               0\n",
      "           Conv2d-45          [-1, 1, 192, 128]              33\n",
      "================================================================\n",
      "Total params: 7,846,081\n",
      "Trainable params: 7,846,081\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.09\n",
      "Forward/backward pass size (MB): 117.00\n",
      "Params size (MB): 29.93\n",
      "Estimated Total Size (MB): 147.02\n",
      "----------------------------------------------------------------\n",
      "Epoch 0/39\n",
      "----------\n",
      "LR 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/bitbucket/rh2515/CrohnsDisease/venv/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:122: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01893678680062294\n",
      "0.018416741862893105\n",
      "0.01750318519771099\n",
      "0.016345517709851265\n",
      "0.015116836875677109\n",
      "0.01388542540371418\n",
      "0.01270214281976223\n",
      "0.011608261615037918\n",
      "0.010967533104121685\n",
      "0.010452117770910263\n",
      "0.0101993503049016\n",
      "0.01009098906069994\n",
      "0.010259639471769333\n",
      "0.010397220030426979\n",
      "0.010685240849852562\n",
      "0.010883726179599762\n",
      "0.011202745139598846\n",
      "0.011247883550822735\n",
      "0.011350240558385849\n",
      "0.01126311905682087\n",
      "0.011245938017964363\n",
      "0.01104987133294344\n",
      "0.011004699394106865\n",
      "0.010866646654903889\n",
      "0.0106572974473238\n",
      "0.010448667220771313\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-34a4901593c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0mexp_lr_scheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStepLR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer_ft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_ft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexp_lr_scheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-34a4901593c9>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, optimizer, scheduler, num_epochs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m                         \u001b[0;31m#print (loss.item())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m                     \u001b[0mloss_vec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m50\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Get a batch of training data\n",
    "inputs, masks = next(iter(dataloaders['train']))\n",
    "\n",
    "print(inputs.shape, masks.shape)\n",
    "print(inputs.dtype, masks.dtype)\n",
    "\n",
    "for x in [inputs.numpy(), masks.numpy()]:\n",
    "    print(x.min(), x.max(), x.mean(), x.std())\n",
    "\n",
    "# install torchsummary first\n",
    "from torchsummary import summary\n",
    "# import model from python file\n",
    "import Unet_pytorch\n",
    "\n",
    "model = Unet_pytorch.UNet(1)\n",
    "model = model.to(device)\n",
    "\n",
    "print(\"MODEL ARCHITECTURE ...\")\n",
    "summary(model, input_size=(1,192,128))\n",
    "\n",
    "# Import other useful libraries \n",
    "from collections import defaultdict\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import time\n",
    "import copy\n",
    "\n",
    "loss_function = nn.MSELoss()\n",
    "\n",
    "def train_model(model, optimizer, scheduler, num_epochs=25):\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_loss = 1e10\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "        \n",
    "        since = time.time()\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                for param_group in optimizer.param_groups:\n",
    "                    print(\"LR\", param_group['lr'])\n",
    "                    \n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            epoch_samples = 0\n",
    "            loss_vec = []\n",
    "\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)             \n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs.float())\n",
    "                    loss = loss_function(torch.squeeze(outputs), labels.type(torch.float32))\n",
    "                    \n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                        #print (loss.item())\n",
    "                    loss_vec.append(loss.item())  \n",
    "\n",
    "                    if epoch % 50 == 0:\n",
    "                        print(loss.item())\n",
    "\n",
    "                # statistics\n",
    "                epoch_samples += inputs.size(0)\n",
    "\n",
    "            # print loss at every epoch \n",
    "            print(np.asarray(loss_vec))\n",
    "            epoch_loss = np.mean(np.asarray(loss_vec), dtype=np.float32)\n",
    "            #epoch_loss = np.mean(np.asarray(loss_vec), dtype=np.float32)/float(epoch_samples)\n",
    "            print('Loss ' + phase, ': {:.4f}'.format(epoch_loss))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_loss < best_loss:\n",
    "                print(\"saving best model\")\n",
    "                best_loss = epoch_loss\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        time_elapsed = time.time() - since\n",
    "        print('{:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val loss: {:4f}'.format(best_loss))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model\n",
    "\n",
    "num_class = 1\n",
    "\n",
    "model = Unet_pytorch.UNet(num_class).float()\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer_ft = optim.SGD(model.parameters(), lr = 0.01, momentum=0.9) \n",
    "\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=25, gamma=0.1)\n",
    "\n",
    "model = train_model(model, optimizer_ft, exp_lr_scheduler, num_epochs=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
